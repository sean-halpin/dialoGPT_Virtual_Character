{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dialog_with_persona.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNl/t8ki0N/DRe9290kDX/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/dialoGPT_Virtual_Character/blob/main/dialog_with_persona.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDGt-vllubgq",
        "outputId": "e33ac50e-d81d-4e43-8016-6dee8599261c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers\n",
        "!pip install flair\n",
        "!pip install word2number"
      ],
      "metadata": {
        "id": "SiJbcfEXuqsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Persona "
      ],
      "metadata": {
        "id": "hivIiXV6xUZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persona = {\n",
        "    \"age inquiry\": \"39\"\n",
        "}"
      ],
      "metadata": {
        "id": "sxp7crLVxXdA"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained dialog req/res model"
      ],
      "metadata": {
        "id": "lhE3RTg_xBp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "# Standard DialoGPT\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "# Transfer Learned DialoGPT\n",
        "# model = AutoModelWithLMHead.from_pretrained(\"output-small\")"
      ],
      "metadata": {
        "id": "cIoWwjHRujHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a pre-trained zero-shot classifier  "
      ],
      "metadata": {
        "id": "jy_64b3CwGkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "95KEfR2bwEzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = ['age inquiry', 'job inquiry', 'name inquiry', 'statement', 'personal detail']"
      ],
      "metadata": {
        "id": "mdVW5bQlxcog"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(sequence_to_classify):\n",
        "  class_result = classifier(sequence_to_classify, candidate_labels)\n",
        "  return {\n",
        "      'label':class_result['labels'][0], \n",
        "      'score':class_result['scores'][0]\n",
        "      }"
      ],
      "metadata": {
        "id": "LWoLAn9Xx_IN"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained NER (Named Entity Recognition) Model"
      ],
      "metadata": {
        "id": "EJDUfXvm00lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-fast\")"
      ],
      "metadata": {
        "id": "1HzRFkoF094g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from word2number import w2n"
      ],
      "metadata": {
        "id": "PU4aM1TtHXVm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_list(tokens):\n",
        "  tkns = []\n",
        "  for t in tokens:\n",
        "    tkns.append(t.text)\n",
        "  return tkns"
      ],
      "metadata": {
        "id": "O5I3GUlv5mGX"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def replace_personal_info(response_str, personal_info_type, persona):\n",
        "  # make example sentence\n",
        "  sentence = Sentence(response_str)\n",
        "  list_tkns = tokens_to_list(sentence)\n",
        "  # predict NER tags\n",
        "  tagger.predict(sentence)\n",
        "  # iterate over entities and print\n",
        "  for entity in sentence.get_spans('ner'):\n",
        "    if personal_info_type == \"age inquiry\":\n",
        "      # print(entity.labels)\n",
        "      # print(entity.id_text)\n",
        "      # print(entity.to_dict())\n",
        "      # print(entity.tokens)\n",
        "      for t in entity.tokens:\n",
        "        for l in t.get_labels():\n",
        "          print(l)\n",
        "          if \"DATE\" in l.value:\n",
        "            try:\n",
        "              if t.text.isnumeric() or w2n.word_to_num(t.text).isnumeric():\n",
        "                # print(t.text)\n",
        "                # print(t.idx)\n",
        "                list_tkns[t.idx - 1] = persona['age inquiry']\n",
        "                return list_tkns\n",
        "            except Exception as e:\n",
        "              print(\"Error: {} - {}\".format(e, t))\n",
        "  return list_tkns"
      ],
      "metadata": {
        "id": "tDvQfMDj1pzJ"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Replacement of Personal Token"
      ],
      "metadata": {
        "id": "5RxHt0b_8N4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(replace_personal_info(\"I am 88 years old\", \"age inquiry\", persona)))\n",
        "print(\" \".join(replace_personal_info(\"I'm 19, what should I know?\", \"age inquiry\", persona)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zp9WZB92ZZl",
        "outputId": "615c44fd-08e0-4eba-c84a-17c502cd4dcd"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-DATE (0.7147)\n",
            "I am 39 years old\n",
            "S-DATE (0.991)\n",
            "I 'm 39 , what should I know ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat"
      ],
      "metadata": {
        "id": "2vbSQM6WxfJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    usr_input = input(\">> User:\")\n",
        "    classification = classify(usr_input)\n",
        "    new_user_input_ids = tokenizer.encode(usr_input + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    num_return_seqs=1\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=100, \n",
        "        top_p=0.7,\n",
        "        temperature = 0.7,\n",
        "        num_return_sequences=num_return_seqs\n",
        "    )\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    botname = \"Bot\"\n",
        "    for i in range(0,num_return_seqs):\n",
        "      bot_output = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][i])\n",
        "      if classification['label'] in persona:\n",
        "        try:\n",
        "          print(\"\\t{}\\n\\t{}\\n\\t{}\".format(bot_output, classification['label'], persona))\n",
        "          bot_output = \" \".join(replace_personal_info(bot_output, classification['label'], persona))\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "      print(\"{}: {}\".format(botname, bot_output, skip_special_tokens=True))\n",
        "\n",
        "    # Reset Chat History\n",
        "    chat_history_ids = chat_history_ids[0].unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "razHC68evgsG",
        "outputId": "a1f8f03f-1725-4d32-9156-aa58cf528414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> User:Hi how old are you\n",
            "\tI'm only 16, but I'm sure I'll grow out of it.<|endoftext|>\n",
            "\tage inquiry\n",
            "\t{'age inquiry': '39'}\n",
            "S-DATE (0.9166)\n",
            "Bot: I 'm only 39 , but I 'm sure I 'll grow out of it. <| endoftext |>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LEX9xNsSvqD_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}