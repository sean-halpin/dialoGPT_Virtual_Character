{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dialog_with_persona.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/dialoGPT_Virtual_Character/blob/main/dialog_with_persona.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers\n",
        "!pip install flair==0.10\n",
        "!pip install word2number"
      ],
      "metadata": {
        "id": "SiJbcfEXuqsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot Persona "
      ],
      "metadata": {
        "id": "hivIiXV6xUZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persona = {\n",
        "    \"age inquiry\": \"39\"\n",
        "}"
      ],
      "metadata": {
        "id": "sxp7crLVxXdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained dialog req/res model"
      ],
      "metadata": {
        "id": "lhE3RTg_xBp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"shalpin87/dialoGPT-homer-simpson\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"shalpin87/dialoGPT-homer-simpson\")"
      ],
      "metadata": {
        "id": "cIoWwjHRujHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a pre-trained zero-shot classifier  "
      ],
      "metadata": {
        "id": "jy_64b3CwGkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "95KEfR2bwEzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = ['age inquiry', 'job inquiry', 'name inquiry', 'statement', 'personal detail']"
      ],
      "metadata": {
        "id": "mdVW5bQlxcog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(sequence_to_classify):\n",
        "  class_result = classifier(sequence_to_classify, candidate_labels)\n",
        "  return {\n",
        "      'label':class_result['labels'][0], \n",
        "      'score':class_result['scores'][0]\n",
        "      }"
      ],
      "metadata": {
        "id": "LWoLAn9Xx_IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load pre-trained NER (Named Entity Recognition) Model"
      ],
      "metadata": {
        "id": "EJDUfXvm00lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-fast\")"
      ],
      "metadata": {
        "id": "1HzRFkoF094g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from word2number import w2n"
      ],
      "metadata": {
        "id": "PU4aM1TtHXVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_list(tokens):\n",
        "  tkns = []\n",
        "  for t in tokens:\n",
        "    tkns.append(t.text)\n",
        "  return tkns"
      ],
      "metadata": {
        "id": "O5I3GUlv5mGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def replace_personal_info(response_str, personal_info_type, persona):\n",
        "  # make example sentence\n",
        "  sentence = Sentence(response_str)\n",
        "  list_tkns = tokens_to_list(sentence)\n",
        "  # predict NER tags\n",
        "  tagger.predict(sentence)\n",
        "  # iterate over entities and print\n",
        "  for entity in sentence.get_spans('ner'):\n",
        "    # print(dir(entity))\n",
        "    if personal_info_type == \"age inquiry\":\n",
        "      # print(entity.labels)\n",
        "      # print(entity.id_text)\n",
        "      # print(entity.to_dict())\n",
        "      # print(entity.tokens)\n",
        "      for t in entity.tokens:\n",
        "        for l in t.labels:\n",
        "          if \"DATE\" in l.value or \"CARDINAL\" in l.value:\n",
        "            try:\n",
        "              if t.text.isnumeric() or w2n.word_to_num(t.text):\n",
        "                # print(t.text)\n",
        "                # print(t.idx)\n",
        "                list_tkns[t.idx - 1] = persona['age inquiry']\n",
        "                return list_tkns\n",
        "            except Exception as e:\n",
        "              print(\"Error: {} - {}\".format(e, t.text.isnumeric()))\n",
        "  return list_tkns"
      ],
      "metadata": {
        "id": "tDvQfMDj1pzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Replacement of Personal Token"
      ],
      "metadata": {
        "id": "5RxHt0b_8N4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\" \".join(replace_personal_info(\"I am 88 years old\", \"age inquiry\", persona)))\n",
        "# print(\" \".join(replace_personal_info(\"I'm 19, what should I know?\", \"age inquiry\", persona)))\n",
        "# print(\" \".join(replace_personal_info(\"20 , you ??\", \"age inquiry\", persona)))\n",
        "# print(\" \".join(replace_personal_info(\"I'm thirty-one.\", \"age inquiry\", persona)))"
      ],
      "metadata": {
        "id": "1Zp9WZB92ZZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat"
      ],
      "metadata": {
        "id": "2vbSQM6WxfJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What is your name?\",\n",
        "    \"Who are you?\",\n",
        "    \"Where do you work?\",\n",
        "    \"Who really killed Mr Burns?\",\n",
        "    \"Have you ever stolen from the Kwik-E-Mart?\",\n",
        "    \"Who was the worst member of the Be Sharps?\",\n",
        "    \"Hey where did Barney Gumble go?\",\n",
        "    \"What is your favorite bar to have a beer?\",\n",
        "    \"What is the best beer in Springfield?\",\n",
        "    \"Is Bart working for the Mob?\",\n",
        "    \"I think there was an incident in sector 7 G\",\n",
        "    \"Is Ned Flanders house okay?\",\n",
        "    \"Oh my god it's Sideshow Bob\",\n",
        "    \"What is a Flaming Moe?\",\n",
        "    \"What is happening to Apu?\",\n",
        "    \"Who quit the band?\",\n",
        "    \"What age are you?\",\n",
        "    \"How old are you?\"\n",
        "]\n",
        "\n",
        "botname = \"HomerBot\"\n",
        "# Let's chat\n",
        "for step in range(len(questions)):\n",
        "    print(\"***************************************\")\n",
        "    # model_input = input(\">> User:\")\n",
        "    model_input = questions[step]\n",
        "    print(\"Q. {}\".format(model_input))\n",
        "    classification = classify(model_input)\n",
        "    new_user_input_ids = tokenizer.encode(model_input + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    bot_input_ids = new_user_input_ids\n",
        "\n",
        "    num_return_seqs=1\n",
        "\n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, \n",
        "        max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=200, \n",
        "        top_p=0.55,\n",
        "        temperature = 0.85,\n",
        "        num_return_sequences=num_return_seqs\n",
        "    )\n",
        "    \n",
        "    botname = \"HomerBot\"\n",
        "    for i in range(0,num_return_seqs):\n",
        "      bot_output = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][i])\n",
        "      if classification['label'] in persona:\n",
        "        try:\n",
        "          # print(\"\\t{}\\n\\t{}\\n\\t{}\".format(bot_output.replace(\"<|endoftext|>\",\"\"), classification['label'], persona))\n",
        "          bot_output = \" \".join(replace_personal_info(bot_output.replace(\"<|endoftext|>\",\"\").replace(\"<| endoftext |>\",\"\"), classification['label'], persona))\n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "      print(\"{}: {}\".format(botname, bot_output.replace(\"<|endoftext|>\",\"\").replace(\"<| endoftext |>\",\"\"), skip_special_tokens=True))\n",
        "\n",
        "    chat_history_ids = []"
      ],
      "metadata": {
        "id": "LEX9xNsSvqD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with User"
      ],
      "metadata": {
        "id": "66BsebST3aos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(5):\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    bot_input_ids = new_user_input_ids\n",
        "    \n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, \n",
        "        max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=200, \n",
        "        top_p=0.55,\n",
        "        temperature = 0.85,\n",
        "    )\n",
        "\n",
        "    print(\"HomerBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n",
        "    chat_history_ids = []"
      ],
      "metadata": {
        "id": "DNTW4jin7IuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wFV6Kh_X3rMG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}